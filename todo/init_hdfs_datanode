- name: set all hdfs data nodes
  hosts: HDFS-DN
  user: root
  gather_facts: yes
  tasks:
    - include_role:
        name: hdfs-datanode
      vars:
        group: HDFS-DN
        extra_group:
          - HDFS-JN
          - HDFS-ZK
        hadoop_pkg: 'http://mirrors.ustc.edu.cn/apache/hadoop/core/hadoop-3.3.0/hadoop-3.3.0.tar.gz'
        rack_info_list: '/root/Playbook-Performance-Test/rackinfo.list'
        http_auth_secret: /data/hadoop-http-auth-signature-secret 
        core_site:
          fs.defaultFS: hdfs://mycluster
          hadoop.tmp.dir: /data/hadoopData/tmp
          fs.trash.interval: 4320
          topology.script.file.name: /data/hadoop-3.3.0/share/topology.sh
          hadoop.http.filter.initializers: org.apache.hadoop.security.AuthenticationFilterInitializer
          hadoop.http.authentication.type: simple
          hadoop.http.authentication.signature.secret.file: /data/hadoop-http-auth-signature-secret
        hdfs_site:
          dfs.nameservices: mycluster
          dfs.ha.namenodes.mycluster: nn1,nn2
          dfs.namenode.rpc-address.mycluster.nn1: hdfs-namenode-1:8020
          dfs.namenode.rpc-address.mycluster.nn2: hdfs-namenode-2:8020
          dfs.namenode.http-address.mycluster.nn1: hdfs-namenode-1:9870
          dfs.namenode.http-address.mycluster.nn2: hdfs-namenode-2:9870
          dfs.client.failover.proxy.provider.mycluster: org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider
          dfs.webhdfs.enabled: "true"
          dfs.datanode.data.dir: /data/hadoopData/dfs/data
          dfs.replication: 3
          dfs.permissions.superusergroup: staff
          dfs.permissions.enabled: "false" 
